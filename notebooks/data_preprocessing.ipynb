{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12657526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting librosa\n",
      "  Downloading librosa-0.10.2.post1-py3-none-any.whl (260 kB)\n",
      "     -------------------------------------- 260.1/260.1 kB 1.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from librosa) (5.1.1)\n",
      "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from librosa) (1.23.5)\n",
      "Requirement already satisfied: numba>=0.51.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from librosa) (0.56.4)\n",
      "Requirement already satisfied: joblib>=0.14 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from librosa) (1.1.1)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from librosa) (1.2.1)\n",
      "Collecting audioread>=2.1.9\n",
      "  Downloading audioread-3.0.1-py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: scipy>=1.2.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from librosa) (1.10.0)\n",
      "Collecting soxr>=0.3.2\n",
      "  Downloading soxr-0.5.0.post1-cp310-cp310-win_amd64.whl (166 kB)\n",
      "     -------------------------------------- 166.9/166.9 kB 3.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: msgpack>=1.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from librosa) (1.0.3)\n",
      "Collecting lazy-loader>=0.1\n",
      "  Using cached lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from librosa) (4.4.0)\n",
      "Collecting soundfile>=0.12.1\n",
      "  Downloading soundfile-0.13.1-py2.py3-none-win_amd64.whl (1.0 MB)\n",
      "     ---------------------------------------- 1.0/1.0 MB 3.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pooch>=1.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from librosa) (1.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\asus\\anaconda3\\lib\\site-packages (from lazy-loader>=0.1->librosa) (22.0)\n",
      "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from numba>=0.51.0->librosa) (0.39.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\asus\\anaconda3\\lib\\site-packages (from numba>=0.51.0->librosa) (65.6.3)\n",
      "Requirement already satisfied: appdirs in c:\\users\\asus\\anaconda3\\lib\\site-packages (from pooch>=1.1->librosa) (1.4.4)\n",
      "Requirement already satisfied: requests in c:\\users\\asus\\anaconda3\\lib\\site-packages (from pooch>=1.1->librosa) (2.28.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from scikit-learn>=0.20.0->librosa) (2.2.0)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from soundfile>=0.12.1->librosa) (1.15.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\asus\\anaconda3\\lib\\site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.21)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests->pooch>=1.1->librosa) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests->pooch>=1.1->librosa) (1.26.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests->pooch>=1.1->librosa) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests->pooch>=1.1->librosa) (3.4)\n",
      "Installing collected packages: soxr, lazy-loader, audioread, soundfile, librosa\n",
      "Successfully installed audioread-3.0.1 lazy-loader-0.4 librosa-0.10.2.post1 soundfile-0.13.1 soxr-0.5.0.post1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install librosa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display\n",
    "import os\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e398311",
   "metadata": {},
   "source": [
    "Loading and Preprocessing for Activity dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06a93591",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Daily Activity Dataset\n",
    "activity_df = pd.read_csv(\"E:\\Final-year-project\\AI-PublicSpeaking-Anxiety\\datasets\\dailyActivity_merged.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c81781c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert ActivityDate to datetime format (if not already)\n",
    "activity_df[\"ActivityDate\"] = pd.to_datetime(activity_df[\"ActivityDate\"])\n",
    "\n",
    "# Change the year to 2024 while keeping the month and day the same\n",
    "activity_df[\"ActivityDate\"] = activity_df[\"ActivityDate\"].apply(lambda x: x.replace(year=2024))\n",
    "\n",
    "# Format it as MM/DD/YYYY\n",
    "activity_df[\"ActivityDate\"] = activity_df[\"ActivityDate\"].dt.strftime(\"%m/%d/%Y\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e241c693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Daily Activity Data Loaded & Preprocessed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_18864\\4003316535.py:2: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  activity_df.fillna(activity_df.mean(), inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ActivityDate</th>\n",
       "      <th>TotalSteps</th>\n",
       "      <th>TotalDistance</th>\n",
       "      <th>TrackerDistance</th>\n",
       "      <th>LoggedActivitiesDistance</th>\n",
       "      <th>VeryActiveDistance</th>\n",
       "      <th>ModeratelyActiveDistance</th>\n",
       "      <th>LightActiveDistance</th>\n",
       "      <th>SedentaryActiveDistance</th>\n",
       "      <th>VeryActiveMinutes</th>\n",
       "      <th>FairlyActiveMinutes</th>\n",
       "      <th>LightlyActiveMinutes</th>\n",
       "      <th>SedentaryMinutes</th>\n",
       "      <th>Calories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1503960366</td>\n",
       "      <td>04/12/2024</td>\n",
       "      <td>0.365418</td>\n",
       "      <td>0.303247</td>\n",
       "      <td>0.303247</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.085766</td>\n",
       "      <td>0.084877</td>\n",
       "      <td>0.565826</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.119048</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.633205</td>\n",
       "      <td>0.505556</td>\n",
       "      <td>0.405102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1503960366</td>\n",
       "      <td>04/13/2024</td>\n",
       "      <td>0.298037</td>\n",
       "      <td>0.248662</td>\n",
       "      <td>0.248662</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.071624</td>\n",
       "      <td>0.106481</td>\n",
       "      <td>0.439776</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.132867</td>\n",
       "      <td>0.418919</td>\n",
       "      <td>0.538889</td>\n",
       "      <td>0.366735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1503960366</td>\n",
       "      <td>04/14/2024</td>\n",
       "      <td>0.290402</td>\n",
       "      <td>0.240457</td>\n",
       "      <td>0.240457</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.111314</td>\n",
       "      <td>0.061728</td>\n",
       "      <td>0.365079</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.349421</td>\n",
       "      <td>0.845833</td>\n",
       "      <td>0.362449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1503960366</td>\n",
       "      <td>04/15/2024</td>\n",
       "      <td>0.271024</td>\n",
       "      <td>0.224046</td>\n",
       "      <td>0.224046</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.097628</td>\n",
       "      <td>0.194444</td>\n",
       "      <td>0.264239</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.138095</td>\n",
       "      <td>0.237762</td>\n",
       "      <td>0.403475</td>\n",
       "      <td>0.504167</td>\n",
       "      <td>0.356122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1503960366</td>\n",
       "      <td>04/16/2024</td>\n",
       "      <td>0.351731</td>\n",
       "      <td>0.291117</td>\n",
       "      <td>0.291117</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.123631</td>\n",
       "      <td>0.063272</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>0.069930</td>\n",
       "      <td>0.426641</td>\n",
       "      <td>0.536806</td>\n",
       "      <td>0.380204</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Id ActivityDate  TotalSteps  TotalDistance  TrackerDistance  \\\n",
       "0  1503960366   04/12/2024    0.365418       0.303247         0.303247   \n",
       "1  1503960366   04/13/2024    0.298037       0.248662         0.248662   \n",
       "2  1503960366   04/14/2024    0.290402       0.240457         0.240457   \n",
       "3  1503960366   04/15/2024    0.271024       0.224046         0.224046   \n",
       "4  1503960366   04/16/2024    0.351731       0.291117         0.291117   \n",
       "\n",
       "   LoggedActivitiesDistance  VeryActiveDistance  ModeratelyActiveDistance  \\\n",
       "0                       0.0            0.085766                  0.084877   \n",
       "1                       0.0            0.071624                  0.106481   \n",
       "2                       0.0            0.111314                  0.061728   \n",
       "3                       0.0            0.097628                  0.194444   \n",
       "4                       0.0            0.123631                  0.063272   \n",
       "\n",
       "   LightActiveDistance  SedentaryActiveDistance  VeryActiveMinutes  \\\n",
       "0             0.565826                      0.0           0.119048   \n",
       "1             0.439776                      0.0           0.100000   \n",
       "2             0.365079                      0.0           0.142857   \n",
       "3             0.264239                      0.0           0.138095   \n",
       "4             0.470588                      0.0           0.171429   \n",
       "\n",
       "   FairlyActiveMinutes  LightlyActiveMinutes  SedentaryMinutes  Calories  \n",
       "0             0.090909              0.633205          0.505556  0.405102  \n",
       "1             0.132867              0.418919          0.538889  0.366735  \n",
       "2             0.076923              0.349421          0.845833  0.362449  \n",
       "3             0.237762              0.403475          0.504167  0.356122  \n",
       "4             0.069930              0.426641          0.536806  0.380204  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Handle Missing Values\n",
    "activity_df.fillna(activity_df.mean(), inplace=True)\n",
    "\n",
    "# Normalize Numeric Columns\n",
    "scaler = MinMaxScaler()\n",
    "activity_df.iloc[:, 2:] = scaler.fit_transform(activity_df.iloc[:, 2:])\n",
    "\n",
    "print(\"Daily Activity Data Loaded & Preprocessed ✅\")\n",
    "activity_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08489837",
   "metadata": {},
   "source": [
    "Weather dataset preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "74f5011e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Weather Dataset\n",
    "weather_df = pd.read_csv(\"E:\\Final-year-project\\AI-PublicSpeaking-Anxiety\\datasets\\Weather-India-12;04;24-12;05;24.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c4c8a16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weather Data Loaded & Preprocessed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:473: RuntimeWarning: All-NaN slice encountered\n",
      "  data_min = np.nanmin(X, axis=0)\n",
      "c:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:474: RuntimeWarning: All-NaN slice encountered\n",
      "  data_max = np.nanmax(X, axis=0)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tavg</th>\n",
       "      <th>tmin</th>\n",
       "      <th>tmax</th>\n",
       "      <th>prcp</th>\n",
       "      <th>snow</th>\n",
       "      <th>wdir</th>\n",
       "      <th>wspd</th>\n",
       "      <th>wpgt</th>\n",
       "      <th>pres</th>\n",
       "      <th>tsun</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-04-12</td>\n",
       "      <td>0.453125</td>\n",
       "      <td>0.314607</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-04-13</td>\n",
       "      <td>0.343750</td>\n",
       "      <td>0.528090</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.232394</td>\n",
       "      <td>0.320312</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.790476</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-04-14</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.426966</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.210938</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-04-15</td>\n",
       "      <td>0.265625</td>\n",
       "      <td>0.269663</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.919014</td>\n",
       "      <td>0.101562</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.980952</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-04-16</td>\n",
       "      <td>0.296875</td>\n",
       "      <td>0.528090</td>\n",
       "      <td>0.120879</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.771127</td>\n",
       "      <td>0.710938</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.876190</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date      tavg      tmin      tmax  prcp  snow      wdir      wspd  \\\n",
       "0 2024-04-12  0.453125  0.314607  0.692308   0.0   NaN  0.000000  0.000000   \n",
       "1 2024-04-13  0.343750  0.528090  0.714286   0.0   NaN  0.232394  0.320312   \n",
       "2 2024-04-14  0.000000  0.426966  0.000000   0.0   NaN  1.000000  0.210938   \n",
       "3 2024-04-15  0.265625  0.269663  0.142857   0.0   NaN  0.919014  0.101562   \n",
       "4 2024-04-16  0.296875  0.528090  0.120879   0.0   NaN  0.771127  0.710938   \n",
       "\n",
       "   wpgt      pres  tsun  \n",
       "0   NaN  0.857143   NaN  \n",
       "1   NaN  0.790476   NaN  \n",
       "2   NaN  1.000000   NaN  \n",
       "3   NaN  0.980952   NaN  \n",
       "4   NaN  0.876190   NaN  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert date column to datetime\n",
    "weather_df[\"date\"] = pd.to_datetime(weather_df[\"date\"])\n",
    "\n",
    "# Handle Missing Values\n",
    "weather_df.fillna(method='ffill', inplace=True)\n",
    "\n",
    "# Normalize Numeric Columns\n",
    "weather_df.iloc[:, 1:] = scaler.fit_transform(weather_df.iloc[:, 1:])\n",
    "\n",
    "print(\"Weather Data Loaded & Preprocessed ✅\")\n",
    "weather_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751d3823",
   "metadata": {},
   "source": [
    "Preprocessing ecg data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1439c6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ECG Dataset\n",
    "\n",
    "ecg_df = pd.read_excel(\"E:\\\\Final-year-project\\\\AI-PublicSpeaking-Anxiety\\\\datasets\\\\ECG_Data.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0c5f61f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Encode categorical columns\n",
    "for col in ['Condition', 'Gender']:  # Replace with actual column names\n",
    "    le = LabelEncoder()\n",
    "    ecg_df[col] = le.fit_transform(ecg_df[col])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d8a2512b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ECG Data Loaded & Preprocessed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_18864\\1527166204.py:5: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  ecg_df.iloc[:, 2:] = scaler.fit_transform(ecg_df.iloc[:, 2:])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject NO.</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Mean HR (bpm)</th>\n",
       "      <th>AVNN (ms)</th>\n",
       "      <th>SDNN (ms)</th>\n",
       "      <th>NN50 (beats)</th>\n",
       "      <th>pNN50 (%)</th>\n",
       "      <th>RMSSD (ms)</th>\n",
       "      <th>LF (ms2)</th>\n",
       "      <th>LF Norm (n.u.)</th>\n",
       "      <th>HF (ms2)</th>\n",
       "      <th>HF Norm (n.u.)</th>\n",
       "      <th>LF/HF Ratio</th>\n",
       "      <th>Condition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.430765</td>\n",
       "      <td>0.404093</td>\n",
       "      <td>0.355569</td>\n",
       "      <td>0.199134</td>\n",
       "      <td>0.150747</td>\n",
       "      <td>0.231421</td>\n",
       "      <td>0.069521</td>\n",
       "      <td>0.393274</td>\n",
       "      <td>0.134682</td>\n",
       "      <td>0.606399</td>\n",
       "      <td>0.078043</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.474443</td>\n",
       "      <td>0.362426</td>\n",
       "      <td>0.105769</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022008</td>\n",
       "      <td>0.050015</td>\n",
       "      <td>0.966936</td>\n",
       "      <td>0.005833</td>\n",
       "      <td>0.032804</td>\n",
       "      <td>0.793558</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.320848</td>\n",
       "      <td>0.520664</td>\n",
       "      <td>0.403147</td>\n",
       "      <td>0.307359</td>\n",
       "      <td>0.245282</td>\n",
       "      <td>0.325777</td>\n",
       "      <td>0.109492</td>\n",
       "      <td>0.379262</td>\n",
       "      <td>0.212762</td>\n",
       "      <td>0.620276</td>\n",
       "      <td>0.073909</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.309438</td>\n",
       "      <td>0.533844</td>\n",
       "      <td>0.305211</td>\n",
       "      <td>0.116883</td>\n",
       "      <td>0.090598</td>\n",
       "      <td>0.200314</td>\n",
       "      <td>0.076305</td>\n",
       "      <td>0.639109</td>\n",
       "      <td>0.068045</td>\n",
       "      <td>0.360683</td>\n",
       "      <td>0.187822</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.040878</td>\n",
       "      <td>0.923316</td>\n",
       "      <td>0.289652</td>\n",
       "      <td>0.233766</td>\n",
       "      <td>0.225417</td>\n",
       "      <td>0.296554</td>\n",
       "      <td>0.060517</td>\n",
       "      <td>0.426804</td>\n",
       "      <td>0.107455</td>\n",
       "      <td>0.572288</td>\n",
       "      <td>0.088723</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Subject NO.  Gender  Mean HR (bpm)  AVNN (ms)  SDNN (ms)  NN50 (beats)  \\\n",
       "0            1       0       0.430765   0.404093   0.355569      0.199134   \n",
       "1            2       0       0.474443   0.362426   0.105769      0.000000   \n",
       "2            3       0       0.320848   0.520664   0.403147      0.307359   \n",
       "3            4       0       0.309438   0.533844   0.305211      0.116883   \n",
       "4            5       0       0.040878   0.923316   0.289652      0.233766   \n",
       "\n",
       "   pNN50 (%)  RMSSD (ms)  LF (ms2)  LF Norm (n.u.)  HF (ms2)  HF Norm (n.u.)  \\\n",
       "0   0.150747    0.231421  0.069521        0.393274  0.134682        0.606399   \n",
       "1   0.000000    0.022008  0.050015        0.966936  0.005833        0.032804   \n",
       "2   0.245282    0.325777  0.109492        0.379262  0.212762        0.620276   \n",
       "3   0.090598    0.200314  0.076305        0.639109  0.068045        0.360683   \n",
       "4   0.225417    0.296554  0.060517        0.426804  0.107455        0.572288   \n",
       "\n",
       "   LF/HF Ratio  Condition  \n",
       "0     0.078043        0.0  \n",
       "1     0.793558        0.0  \n",
       "2     0.073909        0.0  \n",
       "3     0.187822        0.0  \n",
       "4     0.088723        0.0  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Handle Missing Values\n",
    "ecg_df.fillna(ecg_df.mean(), inplace=True)\n",
    "\n",
    "# Normalize Numeric Columns\n",
    "ecg_df.iloc[:, 2:] = scaler.fit_transform(ecg_df.iloc[:, 2:])\n",
    "\n",
    "print(\"ECG Data Loaded & Preprocessed ✅\")\n",
    "ecg_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a16b471",
   "metadata": {},
   "source": [
    "Speech data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1ddd6989",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# File path to dataset\n",
    "file_path = r\"E:\\Final-year-project\\AI-PublicSpeaking-Anxiety\\datasets\\iemocap_full_dataset.csv\"\n",
    "\n",
    "# Load dataset and label it as speech_df\n",
    "speech_df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e8d3ef1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with \"xxx\" in the emotion column (unlabeled data)\n",
    "speech_df = speech_df[speech_df[\"emotion\"] != \"xxx\"]\n",
    "\n",
    "# Reset index after dropping rows\n",
    "speech_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Define base path correctly\n",
    "base_path = r\"E:\\Final-year-project\\AI-PublicSpeaking-Anxiety\\datasets\"\n",
    "\n",
    "# Convert relative paths to absolute paths\n",
    "speech_df[\"absolute_path\"] = speech_df[\"path\"].apply(lambda x: os.path.join(base_path, x.replace(\"/\", \"\\\\\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "903483b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed Speech Dataset Sample:\n",
      "   session  method  gender emotion  n_annotators  agreement  \\\n",
      "0        1  script       1     neu             3          3   \n",
      "1        1  script       1     fru             3          2   \n",
      "2        1  script       1     sur             3          2   \n",
      "3        1  script       1     neu             3          2   \n",
      "4        1  script       1     ang             3          2   \n",
      "\n",
      "                                                path  \\\n",
      "0  Session1/sentences/wav/Ses01F_script02_1/Ses01...   \n",
      "1  Session1/sentences/wav/Ses01F_script02_1/Ses01...   \n",
      "2  Session1/sentences/wav/Ses01F_script02_1/Ses01...   \n",
      "3  Session1/sentences/wav/Ses01F_script02_1/Ses01...   \n",
      "4  Session1/sentences/wav/Ses01F_script02_1/Ses01...   \n",
      "\n",
      "                                       absolute_path  emotion_label  \n",
      "0  E:\\Final-year-project\\AI-PublicSpeaking-Anxiet...              0  \n",
      "1  E:\\Final-year-project\\AI-PublicSpeaking-Anxiet...              1  \n",
      "2  E:\\Final-year-project\\AI-PublicSpeaking-Anxiet...              2  \n",
      "3  E:\\Final-year-project\\AI-PublicSpeaking-Anxiet...              0  \n",
      "4  E:\\Final-year-project\\AI-PublicSpeaking-Anxiet...              3  \n",
      "Preprocessing complete. Dataset saved as 'preprocessed_speech_dataset.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Encode categorical variables\n",
    "speech_df[\"gender\"] = speech_df[\"gender\"].map({\"M\": 0, \"F\": 1})  # Convert gender to 0 (Male) and 1 (Female)\n",
    "emotion_mapping = {e: i for i, e in enumerate(speech_df[\"emotion\"].unique())}\n",
    "speech_df[\"emotion_label\"] = speech_df[\"emotion\"].map(emotion_mapping)\n",
    "\n",
    "# Print basic dataset info\n",
    "print(\"Processed Speech Dataset Sample:\")\n",
    "print(speech_df.head())\n",
    "\n",
    "# Save preprocessed data for integration\n",
    "speech_df.to_csv(r\"E:\\Final-year-project\\AI-PublicSpeaking-Anxiety\\datasets\\preprocessed_speech_dataset.csv\", index=False)\n",
    "\n",
    "print(\"Preprocessing complete. Dataset saved as 'preprocessed_speech_dataset.csv'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a80d78",
   "metadata": {},
   "source": [
    "Merged dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c9773737",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "You are trying to merge on object and datetime64[ns] columns. If you wish to proceed you should use pd.concat",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Merge Daily Activity & Weather Data\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m combined_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\u001b[43mactivity_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweather_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mActivityDate\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdate\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Merge with ECG Data on Subject NO\u001b[39;00m\n\u001b[0;32m      5\u001b[0m combined_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mmerge(combined_df, ecg_df, left_on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mId\u001b[39m\u001b[38;5;124m\"\u001b[39m, right_on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSubject NO.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:110\u001b[0m, in \u001b[0;36mmerge\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;129m@Substitution\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mleft : DataFrame or named Series\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     94\u001b[0m \u001b[38;5;129m@Appender\u001b[39m(_merge_doc, indents\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmerge\u001b[39m(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    108\u001b[0m     validate: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    109\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[1;32m--> 110\u001b[0m     op \u001b[38;5;241m=\u001b[39m \u001b[43m_MergeOperation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    111\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    112\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    113\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    114\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    115\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    116\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    117\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    119\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    120\u001b[0m \u001b[43m        \u001b[49m\u001b[43msuffixes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuffixes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    121\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindicator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindicator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    123\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result(copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:707\u001b[0m, in \u001b[0;36m_MergeOperation.__init__\u001b[1;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, indicator, validate)\u001b[0m\n\u001b[0;32m    699\u001b[0m (\n\u001b[0;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft_join_keys,\n\u001b[0;32m    701\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright_join_keys,\n\u001b[0;32m    702\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjoin_names,\n\u001b[0;32m    703\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_merge_keys()\n\u001b[0;32m    705\u001b[0m \u001b[38;5;66;03m# validate the merge keys dtypes. We may need to coerce\u001b[39;00m\n\u001b[0;32m    706\u001b[0m \u001b[38;5;66;03m# to avoid incompatible dtypes\u001b[39;00m\n\u001b[1;32m--> 707\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_coerce_merge_keys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    709\u001b[0m \u001b[38;5;66;03m# If argument passed to validate,\u001b[39;00m\n\u001b[0;32m    710\u001b[0m \u001b[38;5;66;03m# check if columns specified as unique\u001b[39;00m\n\u001b[0;32m    711\u001b[0m \u001b[38;5;66;03m# are in fact unique.\u001b[39;00m\n\u001b[0;32m    712\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validate \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:1346\u001b[0m, in \u001b[0;36m_MergeOperation._maybe_coerce_merge_keys\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1344\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m   1345\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m needs_i8_conversion(lk\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mand\u001b[39;00m needs_i8_conversion(rk\u001b[38;5;241m.\u001b[39mdtype):\n\u001b[1;32m-> 1346\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m   1347\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(lk\u001b[38;5;241m.\u001b[39mdtype, DatetimeTZDtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[0;32m   1348\u001b[0m     rk\u001b[38;5;241m.\u001b[39mdtype, DatetimeTZDtype\n\u001b[0;32m   1349\u001b[0m ):\n\u001b[0;32m   1350\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n",
      "\u001b[1;31mValueError\u001b[0m: You are trying to merge on object and datetime64[ns] columns. If you wish to proceed you should use pd.concat"
     ]
    }
   ],
   "source": [
    "# Merge Daily Activity & Weather Data\n",
    "combined_df = pd.merge(activity_df, weather_df, left_on=\"ActivityDate\", right_on=\"date\")\n",
    "\n",
    "# Merge with ECG Data on Subject NO\n",
    "combined_df = pd.merge(combined_df, ecg_df, left_on=\"Id\", right_on=\"Subject NO.\")\n",
    "\n",
    "print(\"All Datasets Merged Successfully ✅\")\n",
    "combined_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
